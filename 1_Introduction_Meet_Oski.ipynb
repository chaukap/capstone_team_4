{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Differential Privacy Mechanisms : Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Differential Privacy](./images/streamlinehq-protect-privacy-4-users-200.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential privacy is a set of mechanisms for publicly sharing information about a dataset by describing the patterns of groups within the dataset while limiting the disclure of information about individuals in the dataset. The goal is to enable gaining insights about a population while protecting the privacy of individuals. \n",
    "\n",
    "- Differential Privacy offers mathematical guarantees about the level of privacy afforded an individual.  These mathematical guarantees make the mechanisms attractive as a means of protection. \n",
    "\n",
    "- Differential Privacy mechanisms act as a filter of the true responses from queries to a database.  These filters perturb the true answers just enough to keep the contributions of individual records private. These types of queries are typically referred to as \"aggregation queries\".\n",
    "\n",
    "- In practice, if implemented appropriately, differentially private queries will return answers that are a) useful and b) keep an individual's membsherip in the database private\n",
    "\n",
    "- In theory, differential privacy results can provide mathematical gaurantees on the level of privacy afforded.  This is what makes them most attractive.\n",
    "\n",
    "- All differential privacy mechanisms work by injecting a perturbation in the output of a query.  What? Thats right, the answer returned by the query differs potentially from the true answer!\n",
    "\n",
    "- The perturbation comes in the form of either adding \"noise\"  to the true answer (adding or subtracting a random amount from the true answer) as is the case with **Laplacian Mechanisms** or **Gaussian Mechanisms**, or potentially returning the wrong answer some times, as is the case with **Exponential Mechanisms**.\n",
    "\n",
    "- Now that we understand what Differntial Privacy tries to guarantee on an intuitive level, we want to add a \"knob\" that determines the level of that protection.  We can turn the knob (or knobs) to increase or decrease the level of privacy. The first knob comes in the form of the parameter $\\epsilon$. The second knob comes in the form of the parameter $\\Delta$.\n",
    "\n",
    "- **Think lower $\\epsilon$, higher privacy!** \n",
    "\n",
    "- Envision $\\epsilon$ as a knob.  \n",
    "\n",
    "![Knob](./images/volume.PNG)\n",
    "\n",
    "- The higher you turn the knob, the lower the privacy.\n",
    "\n",
    "- Practical implementations require the careful choice of $\\epsilon$ and $\\Delta$ to produce privacy in practice and useful results from queries.\n",
    "\n",
    "Next, let's explore how to set the parameters for our differential privacy mechanisms in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting the Parameter Epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two important paremeters in differential privacy mechanisms are **$\\epsilon$** and **$\\Delta$**.  \n",
    "\n",
    "Here we first consider the \"privacy\" parameter $\\epsilon$. \n",
    "\n",
    "The symbol may not be that familar as it never made it as a big time COVID-19 variant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Epsilon](./images/epsilon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - $\\epsilon$ is the parameter that sets the level of the privacy guarantee and affects the level of utility of the results returned from queries to the database.\n",
    " \n",
    "- Recall that by adding carefully crafted noise to the outcome of the mechanism just enough uncertainty is added to mask the membership of any one record in the database. $\\epsilon$ is perhaps the most important parameter that determines how much noise is added to the outcome.\n",
    "\n",
    "- Changes in $\\epsilon$  will impact both the privacy guarantees afforded to the members of the database and the utility of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Selecting Epsilon for the Right Balance of Privacy and Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you might be wondering what happens if you set $\\epsilon$ as low as possible. **The information gained from the query result will eventually become worthlessif you lower epsilon too much!** The answer to a query will become so noisy, so skewed from the actual answer, that no insights will be able to be gained. **So balancing privacy with utility is the key!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Some Practical Facts About Epsilon and Simple DIfferential Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simply put $\\epsilon$ is a measure of **privacy loss or leakage**.  \n",
    "\n",
    "- Thus, higher epsilon values translate to lower privacy.  \n",
    "\n",
    "- A ‘good’ $\\epsilon$ value should be low and at the same time maintain a certain level of utility of the answers provided by the DP mechanism. \n",
    "\n",
    "- $\\epsilon$ ranges higher than 4 or 5 typically offer diminishing privacy guarantees so much so as really translte to no privacy (although the second parameter $\\Delta$ does affect this claim).\n",
    "\n",
    "- $\\epsilon$ values below 1 tend to diminish utility to the point of being impractical (so much noise in the answer its not helpful)\n",
    "\n",
    "- Simple Differential Privacy (SDP) offeres $\\epsilon$ ranges between .1 and 4, a reasonably practical range \n",
    "\n",
    "- SDP offers $\\epsilon$ offers values to be set by .1 increments \n",
    "\n",
    "- $\\epsilon$ is a setting like a water faucet the higher you turn the knob, the more privacy that leaks (or gushes) out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 The Mathematical Relationship Between $\\epsilon$ and Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Very generally privacy guarentees are met by bounding the differences in the probabilities of outcomes between queries from two databases that differ by only one record.\n",
    "\n",
    "- Bounding this difference protects individual records.\n",
    "\n",
    "- Very generalley turning up $\\epsilon$ one whole number, say from 1 to 2, decreases privacy by a factor of e, or 2.718 (all other parameters held equal)\n",
    "\n",
    "- The mathematics of differential privacy are such that $\\epsilon$ from 1 to 5 make the probability of an outcome being returned by a Laplace mechanism over 100 times more likely.  Thus if initially an outcome was less than 3% likely with an $\\epsilon$ value of 1 it is over 100% (not private at all) with an $\\epsilon$ of 5\n",
    "\n",
    "- If you are interested the mathematical aspects of differential privacy, subsequent notebooks take a deeper dive and present functions for experimentation with parameters and use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Putting the Choice of $\\epsilon$  Into Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier the trade-off between utility and privacy is a **inverse** relationship, privacy goes up, utility goes down. At a high level, as a general concept is depicted by the following illustration.  This illstration contains the accuracy levels in terms of precision from a Bayesian classifer model where the inputs are injected with various levels of Laplacian noise over a range of $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Epsilon](./images/Trade-off-between-privacy-and-utility-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While this illustration is a specific use case it illustrates a general trend that can provide practical guidance.\n",
    "- For values of $\\epsilon$ greater than 4 or 5 there is not significant gains in accuracy (here a proxy for utility).\n",
    "- For $\\epsilon$ < .1 now distinguable deterioration of utility are observed (utility has degraded about as far as it goes).\n",
    "- The range of $\\epsilon$ provided by SMP is [.1, 5]\n",
    "- However, there is no exact right answer! The choice depends on the application.\n",
    "- The key is to find the point where the acceptable privacy and acceptable utility meet.\n",
    "- Utility depends on acceptable accuracy for a particular use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A Simple Example: Oski (Go Bears!) and the Balding Brown Bears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Oski](./images/oski.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are studying the impact of dietary habits of the brown bear and the implications of diet on the loss of fur of our salmon eating friends. The database contains a list of bears, all of whom are losing their fur.  They are balding.  No self-respecting bear wants such a sensitive fact made public. Disclosure of a bear's membership in this database means breaching the privacy of the bear's senstive attribute: they are going bald.\n",
    "\n",
    "Consider the facts around the balding bears database.\n",
    "\n",
    "- When the salmon are running large, talented and strong brown bears can catch in excess of 30 salmon per day, with some outstanding bears, eating possibly up to 50 salmon per day.\n",
    "- In this example, we assume that it is a physical impossiblity that a brown bear can eat more than 50 salmon per day.\n",
    "- Lesser talented, \"normal\" bears tend to collect and eat 10 - 20 salmon per day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CalSal](./images/California_Salmon.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a database of ten bears, all somewhat average brown bears, who are all balding.  Initially we have 10 bears in the database.\n",
    "\n",
    "1. Avalanche (Kutztown)\n",
    "2. Bananas (U of Maine)\n",
    "3. Benny (Morgan State)\n",
    "4. Boomer (Lake Forest)\n",
    "5. Grizz (Oakland)\n",
    "6. Kody (Cascadia)\n",
    "7. Monte (U Montana)\n",
    "8. Nanook (Bowdoin)\n",
    "9. Ranger (Drew)\n",
    "10. Scott Highlander (UC Riverside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a particular day, July 30, when the salmon are running the database records the following number of fish captured by this group.\n",
    "\n",
    "[10, 13, 14, 12, 18, 14, 18, 17, 16, 12]\n",
    "\n",
    "**Note: the eating habits of this entire group falls within a reasonable range of \"normal\" brown bear daily catches!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to understand some statistics about this group of bears without divulging the actual catches of a particular brown bear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true average is 14.4.\n",
    "\n",
    "Using a Laplacian mechanism with **$\\epsilon$ = 1** (**reasonably high privacy**), we ask what is the differentially private average catch on July 30th? \n",
    "\n",
    " With 10 runs of the Laplacian Diffierential Privacy Mechanism the noisy average output is\n",
    " \n",
    " - 15.39\n",
    " - 14.34\n",
    " - 15.26\n",
    " - 11.49\n",
    " - 10.26\n",
    " - 14.16\n",
    " - 12.68\n",
    " - 13.85\n",
    " - 20.14\n",
    " - 14.56\n",
    " \n",
    "Here the MSE or mean square error of the 10 query results from the true average is **6.36**. That is a lot of noise relative to the true average!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Laplacian mechanism with **$\\epsilon$ = 4** (**reasonably low privacy**), we ask what is the average catch on July 30th?\n",
    "\n",
    "With 10 runs we see a much tigher band around the true answer. With higher $\\epsilon$ comes lower protection of privacy.\n",
    "\n",
    "- 13.10\n",
    "- 13.83\n",
    "- 15.33\n",
    "- 15.27\n",
    "- 16.31\n",
    "- 14.10\n",
    "- 14.68\n",
    "- 13.56\n",
    "- 13.28\n",
    "- 13.76\n",
    "\n",
    "Here the Mean Square Error of the 10 query results is **.98**.  The actual query results are close to the true answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What conclusions can we draw from this example?\n",
    "\n",
    "- The choice of $\\epsilon$ boils down to tolerable error in the results for a given dataset\n",
    "- One important factor is that we considered only the utility privacy trade-off for a pretty **homegeneous** group of bears. All bears ate an amount of salmon in the range of 10-18\n",
    "- With this homegenous group it is pretty hard to figure out **under either $\\epsilon$ value** whether any particular bear is in the data set.  \n",
    "\n",
    "- This distribution of data, fairly homogeneous in nature motivates a lower privacy gaurantee and more utility!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What if we needed to protect the privacy of outlier bear we well, one such as Oski?**\n",
    "What if the database, in general had to protect a wider range of dietary habits of our salmon eaters? Not only is the protection important but perhaps the outliers hold the key to uncovering a cure for the balding bears?\n",
    "\n",
    "It is well known that **Oski the Cal Bear** is a giant among bears. What if we have auxillary information about Oski?  Namely, true to his school population he is talented, competitive, clever, and innovative and ee may be able to catch **40-50** salmon a day when they are running!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's add Oski to the database. To keep the fact that Oski is in this database private, it will take more work from our privacy parameters!**\n",
    "\n",
    "*Note: here we increase the sensitivity parameter to account for outliers such as Oski without explanation.  We explore this in depth in notebook 3.  We do this hone our focus on $\\epsilon$.*\n",
    "\n",
    "Let's start by using the same value for $\\epsilon$ = 4, and compare the results to the previous run without Oski."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose Oski records 48 salmon caught on July 30th? Look at the results with $\\epsilon$ = 4. The true average with Oski is $17.46$.\n",
    "\n",
    "- 15.70\n",
    "- 17.45\n",
    "- 18.35\n",
    "- 16.35\n",
    "- 15.90\n",
    "- 17.40\n",
    "- 15.72\n",
    "- 17.97\n",
    "- 18.37\n",
    "- 19.10\n",
    "\n",
    "Compare these results with those where Oski is not in the database.  The MSE from the new true average 17.46 is very low, 1.42. Observations from these queries would tend to convince an adversary that the additional bear was a hefty eater.\n",
    "\n",
    "We know Oski is a skilled, voracious hunter.  Thus we can guess with better odds that Oski is probably in the database.\n",
    "\n",
    "This violates our differential privacy goal! Outliers like Oski in a database need lower values of $\\epsilon$ to mask their membership and thus protect their sensitive attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to effectively mask Oski's membership in the database? What $\\epsilon$ value would we need to accomplish this?\n",
    "\n",
    "Look what happens if we choose $\\epsilon$ = 1 and run the Laplace Mechanism 10 times with Oski in the database.\n",
    "\n",
    "\n",
    "\n",
    "Before:\n",
    "- 15.39\n",
    "- 14.34\n",
    "- 15.26\n",
    "- 11.49\n",
    "- 10.26\n",
    "- 14.16\n",
    "- 12.68\n",
    "- 13.85\n",
    "- 20.14\n",
    "- 14.56\n",
    "\n",
    "\n",
    "After:\n",
    "\n",
    "- 20.06\n",
    "- 17.76\n",
    "- 15.21\n",
    "- 19.20\n",
    "- 19.24\n",
    "- 17.47\n",
    "- 15.29\n",
    "- 24.38\n",
    "- 9.18\n",
    "- 15.91\n",
    "\n",
    "**What do these numbers tell us?**\n",
    "\n",
    "- With $\\epsilon$ = 1 with Oski i the database there is enough noise to cover the shift in the average from 14.4 to 17.46.  The MSE respectively is **6.36** and **14.15**.  This is a rough measure of the coverage of the averages.\n",
    "\n",
    "- The values are so noisy as to make the probabilty of learning of his presense in the database highly unlikely!\n",
    "\n",
    "- With $\\epsilon = 4$ the MSE is much lower without Oski and with Oski respectively is 1.41 and 1.35.  An attacker is going to see with much higher probability the difference between the two averages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What did we learn from protecting Oski?**\n",
    "\n",
    "- The value for $\\epsilon$ depends on the level of privacy needed for a particular use case\n",
    "\n",
    "- Both the variablity of the data and level of protection desired drives the choice.  \n",
    "- If the range of the data is not highly variable, $\\epsilon$ can be higher, imparting more accuracy.  \n",
    "- If the use case needs less protection for outliers, because they may not even be possible in the data, use of a higher value of $\\epsilon$ \n",
    "- However, if protection must extend to extreme cases in the database, $\\epsilon$ must be much lower, typically between 1 and 0.\n",
    "- There is a hefty loss of utility between 1 and 4. Tolerable utility degradation is use case specific, data specific.\n",
    "- Parameter tuning and privacy decision must be made carefully, with study anbd experimentation on the database itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
